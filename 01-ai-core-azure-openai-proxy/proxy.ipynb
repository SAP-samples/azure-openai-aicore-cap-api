{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Install AI Core Python SDK"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ai-api-client-sdk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import requests\n",
                "import time\n",
                "import yaml\n",
                "from IPython.display import clear_output\n",
                "from pprint import pprint\n",
                "\n",
                "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client\n",
                "from ai_api_client_sdk.models.status import Status\n",
                "from ai_api_client_sdk.models.target_status import TargetStatus\n",
                "from ai_api_client_sdk.models.parameter_binding import ParameterBinding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "aic_service_key_path = \"./resources/aic_service_key.json\"\n",
                "git_setup_file_path = \"./resources/git_setup.json\"\n",
                "docker_secret_file_path = \"./resources/docker_secret.json\"\n",
                "env_file_path = \"./resources/env.json\"\n",
                "resource_group = \"azure-openai-aicore\"\n",
                "serving_workflow_file = \"./scenario/proxy.yaml\"\n",
                "connection_name = \"default\"\n",
                "path_prefix = \"app\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Connect to your AI Core instance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(aic_service_key_path) as ask:\n",
                "    aic_service_key = json.load(ask)\n",
                "\n",
                "# AI API client that talks to the AI Core instance.\n",
                "ai_api_client = AIAPIV2Client(\n",
                "    base_url = aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\", # The present AI API version is 2\n",
                "    auth_url=  aic_service_key[\"url\"] + \"/oauth/token\",\n",
                "    client_id = aic_service_key[\"clientid\"],\n",
                "    client_secret = aic_service_key[\"clientsecret\"]\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Onboard the Git repository that contains the templates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(git_setup_file_path) as gs:\n",
                "\t\tsetup_json = json.load(gs)\n",
                "\n",
                "repo_json = setup_json[\"repo\"]\n",
                "\n",
                "response = ai_api_client.rest_client.post(\n",
                "\t\tpath=\"/admin/repositories\",\n",
                "\t\tbody={\n",
                "\t\t\t\t\"name\": repo_json[\"name\"],\n",
                "\t\t\t\t\"url\": repo_json[\"url\"],\n",
                "\t\t\t\t\"username\": repo_json[\"username\"],\n",
                "\t\t\t\t\"password\": repo_json[\"password\"]\n",
                "\t\t}\n",
                ")\n",
                "print(response)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Register an application"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_json = setup_json[\"app\"]\n",
                "response = ai_api_client.rest_client.post(\n",
                "\t\tpath=\"/admin/applications\",\n",
                "\t\tbody={\n",
                "\t\t\t\t\"applicationName\": app_json[\"applicationName\"],\n",
                "\t\t\t\t\"repositoryUrl\": app_json[\"repositoryUrl\"],\n",
                "\t\t\t\t\"revision\": app_json[\"revision\"],\n",
                "\t\t\t\t\"path\": app_json[\"path\"]\n",
                "\t\t}\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4 Docker Hub (optional)\n",
                "#### 4.1 Register Docker secret on SAP BTP, AI Core (optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(docker_secret_file_path) as dsf:\n",
                "    docker_secret = json.load(dsf)\n",
                "\n",
                "pprint(docker_secret)\n",
                "\n",
                "response = ai_api_client.rest_client.post(\n",
                "    path=\"/admin/dockerRegistrySecrets\",\n",
                "    body={\n",
                "        \"name\": docker_secret[\"name\"],\n",
                "        \"data\": docker_secret[\"data\"]\n",
                "    }\n",
                ")\n",
                "print(response)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 4.2 Build and push Docker image (optional)\n",
                "```\n",
                "$ cd proxy\n",
                "$ docker build -t {DOCKER_USERNAME}/azure-openai-proxy .\n",
                "$ docker push {DOCKER_USERNAME}/azure-openai-proxy\n",
                "```\n",
                "\n",
                "THROUGH THE DOCKER CLI.  \n",
                "See: https://developers.sap.com/tutorials/ai-core-aiapi-clientsdk-workflows.html#f824a41d-efe8-4883-8238-caef4ac5f789"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Create a resource group"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai_api_client.rest_client.post(\n",
                "    path=\"/admin/resourceGroups\",\n",
                "    body={\n",
                "        \"resourceGroupId\": resource_group\n",
                "    }\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Create configuration to serve the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create another AI API client to use different base url.\n",
                "ai_api_v2_client = AIAPIV2Client(\n",
                "    base_url=aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2/lm\",\n",
                "    auth_url=aic_service_key[\"url\"] + \"/oauth/token\",\n",
                "    client_id=aic_service_key[\"clientid\"],\n",
                "    client_secret=aic_service_key[\"clientsecret\"],\n",
                "    resource_group=resource_group)\n",
                "\n",
                "with open(serving_workflow_file) as swf:\n",
                "    serving_workflow = yaml.safe_load(swf)\n",
                "\n",
                "scenario_id = serving_workflow[\"metadata\"][\"labels\"][\"scenarios.ai.sap.com/id\"]\n",
                "executable_name = serving_workflow[\"metadata\"][\"name\"]\n",
                "\n",
                "with open(env_file_path) as efp:\n",
                "    environment_values = json.load(efp)\n",
                "\n",
                "parameter_bindings = [ParameterBinding(key=key, value=value) for key, value in environment_values.items()]\n",
                "\n",
                "\n",
                "serve_configuration = {\n",
                "    \"name\": f\"{resource_group}-serve\",\n",
                "    \"scenario_id\": scenario_id,\n",
                "    \"executable_id\": executable_name,\n",
                "    \"parameter_bindings\": parameter_bindings,\n",
                "    \"input_artifact_bindings\": []\n",
                "}\n",
                "\n",
                "serve_config_resp = ai_api_v2_client.configuration.create(**serve_configuration)\n",
                "\n",
                "assert serve_config_resp.message == \"Configuration created\"\n",
                "\n",
                "pprint(vars(serve_config_resp))\n",
                "print(\"configuration for serving the model created\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Actually serve the proxy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "deployment_resp = ai_api_v2_client.deployment.create(serve_config_resp.id)\n",
                "pprint(vars(deployment_resp))\n",
                "\n",
                "# Poll deployment status.\n",
                "status = None\n",
                "while status != Status.RUNNING and status != Status.DEAD:\n",
                "    time.sleep(5)\n",
                "    clear_output(wait=True)\n",
                "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
                "    status = deployment.status\n",
                "    print(\"...... deployment status ......\", flush=True)\n",
                "    print(deployment.status)\n",
                "    pprint(deployment.status_details)\n",
                "\n",
                "    if deployment.status == Status.RUNNING:\n",
                "        print(f\"Deployment with {deployment_resp.id} complete!\")\n",
                "\n",
                "# Allow some time for deployment URL to get ready.\n",
                "time.sleep(10)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Do an inference request"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "endpoint = f\"{deployment.deployment_url}/v2/envs\"\n",
                "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
                "           \"ai-resource-group\": resource_group,\n",
                "           \"Content-Type\": \"application/json\"}\n",
                "response = requests.get(endpoint, headers=headers)\n",
                "\n",
                "legacy_davinci = False # set True if you have a davinci model deployment on Azure OpenAI Services\n",
                "if legacy_davinci:\n",
                "    body = {\n",
                "        \"engine\": \"<YOUR ENGINE>\", # include your davinci engine from a deployment of an Azure OpenAI services model\n",
                "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
                "        \"max_tokens\": 60,\n",
                "        \"temperature\": 0,\n",
                "        \"frequency_penalty\": 0,\n",
                "        \"presence_penalty\": 0,\n",
                "        \"top_p\": 1,\n",
                "        \"best_of\": 1,\n",
                "        \"stop\": \"null\"\n",
                "    }\n",
                "    endpoint = f\"{deployment.deployment_url}/v2/completion\"\n",
                "else:\n",
                "    body = {\n",
                "        \"engine\": \"<YOUR ENGINE>\", # include your engine from a deployment of an Azure OpenAI services model\n",
                "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
                "        \"max_tokens\": 60,\n",
                "        \"temperature\": 0,\n",
                "        \"frequency_penalty\": 0,\n",
                "        \"presence_penalty\": 0,\n",
                "        \"stop\": \"null\"\n",
                "    }\n",
                "    endpoint = f\"{deployment.deployment_url}/v2/chat-completion\"\n",
                "\n",
                "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
                "           \"ai-resource-group\": resource_group,\n",
                "           \"Content-Type\": \"application/json\"}\n",
                "response = requests.post(endpoint, headers=headers, json=body)\n",
                "\n",
                "print(\"Inference result:\", response.json())\n",
                "pprint(vars(response))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9. Kill deployment (optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delete_resp = ai_api_v2_client.deployment.modify(deployment_resp.id,\n",
                "                                                 target_status=TargetStatus.STOPPED)\n",
                "status = None\n",
                "while status != Status.STOPPED:\n",
                "    time.sleep(5)\n",
                "    clear_output(wait=True)\n",
                "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
                "    status = deployment.status\n",
                "    print(\"...... killing deployment ......\", flush=True)\n",
                "    print(f\"Deployment status: {deployment.status}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
